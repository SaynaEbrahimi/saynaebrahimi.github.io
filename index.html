<!-- This entire file shamelessly stolen as-is from Jon Barron's website: http://www.cs.berkeley.edu/~barron/ -->

<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<!-- saved from url=(0035)http://www.cs.berkeley.edu/~barron/ -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    a {
    color: #1772d0;
    text-decoration:none;
    }
    a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
    }
    body,td,th,tr,p,a {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 15px
    }
    strong {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 16px;
    }
    heading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 22px;
    }
    papertitle {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 19px;
    font-weight: 700
    }
    name {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 32px;
    }
    .one
    {
    width: 160px;
    height: 160px;
    position: relative;
    }
    .two
    {
    width: 160px;
    height: 160px;
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
    }
    .fade {
     transition: opacity .2s ease-in-out;
     -moz-transition: opacity .2s ease-in-out;
     -webkit-transition: opacity .2s ease-in-out;
    }
  </style>

<script type="text/javascript">
  function visibility_on(id) {
       var e = document.getElementById(id+"_text");
       if(e.style.display == 'none')
           e.style.display = 'block';
       var e = document.getElementById(id+"_img");
       if(e.style.display == 'none')
           e.style.display = 'block';
  }
  function visibility_off(id) {
       var e = document.getElementById(id+"_text");
       if(e.style.display == 'block')
           e.style.display = 'none';
       var e = document.getElementById(id+"_img");
       if(e.style.display == 'block')
           e.style.display = 'none';
  }
  function toggle_visibility(id) {
      var e = document.getElementById(id+"_text");
      if(e.style.display == 'inline')
         e.style.display = 'block';
      else
         e.style.display = 'inline';
      var e = document.getElementById(id+"_img");
      if(e.style.display == 'inline')
         e.style.display = 'block';
      else
         e.style.display = 'inline';
  }
  function toggle_vis(id) {
      var e = document.getElementById(id);
      if (e.style.display == 'none')
          e.style.display = 'inline';
      else
          e.style.display = 'none';
  }
</script>

  
  <title>Sayna Ebrahimi</title>

  <link href="./jon_barron_website_files/css" rel="stylesheet" type="text/css">
  </head>
  <body>

  <table width="900" border="0" align="center" cellspacing="0" cellpadding="0">
    <tbody><tr>
    <td>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tbody><tr>
        <td width="50%" valign="middle">
        <p align="center">
          <name>Sayna Ebrahimi</name><br>
          </p>
          I am a senior research scientist at <a href="https://research.google/people/SaynaEbrahimi/"> Google DeepMind</a>. I completed my PhD at the loveliest of universities, <a href="https://bair.berkeley.edu/"  >UC Berkeley's Artificial Intelligence Research (BAIR) lab </a> where I was advised by <a href="http://people.eecs.berkeley.edu/~trevor/" >Trevor Darrell</a> and <a href="https://www.me.berkeley.edu/people/faculty/david-steigmann" > David Steigmann</a>. During my PhD, I spent time at <a href="https://research.fb.com/category/facebook-ai-research/"> Facebook AI Research</a> and NVIDIA as a research intern.  

          Outside work, you can find me lifting weights, running, or playing with my ever-enthusiastic dog, <a href="https://github.com/SaynaEbrahimi/saynaebrahimi.github.io/blob/master/Pashmak.jpg?raw=true"> Pashmak</a>.
        </li>


        <p align="center">
<a href="mailto:sayna@berkeley.edu">Email</a> &nbsp;/&nbsp;
<a href="./index_files/bio.html">Bio</a> &nbsp;/&nbsp;
<!-- <a href="./SaynaEbrahimi_CV.pdf">CV</a> &nbsp;/&nbsp; -->
<a href="https://scholar.google.com/citations?user=wRyjJfMAAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
<a href="https://github.com/SaynaEbrahimi/"> Github </a> &nbsp;/&nbsp;
<!-- <a href="https://www.linkedin.com/in/saynaebrahimi"> LinkedIn </a> &nbsp;/&nbsp; -->
<a href="https://twitter.com/SaynaEbrahimi"> Twitter </a> &nbsp;/&nbsp;
<a href="https://www.facebook.com/sayna.ebrahimi"> Facebook </a> 
<!-- &nbsp;/&nbsp; -->
<!-- <a href="https://www.facebook.com/sayna.ebrahimi"> Facebook </a> -->

        </p>
        </td>
        <td 
        style="padding:2.5%;width:30%;max-width:30%">
              <a href="./mypic.JPG"><img style="width:100%;max-width:100%" alt="profile photo" src="./circle-cropped.png" class="hoverZoomLink"></a>        
        </td>
      </tr>
      </tbody></table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tbody><tr>
        <td width="100%" valign="middle">
          <heading>Research</heading>
          <p>        
            My research is on large-scale multi-modal generation and understanding. During my PhD, I focused on efficient learning and domain adaptation in computer vision. 
          </p>
        </td>
      </tr>
      </tbody></table>

      <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tbody><tr>
        <td width="100%" valign="middle">
          <heading><em><strong>Interested in interning at Google?</em></strong></heading>
          <p> 
                <em><strong>I am actively looking for motivated PhD student interns/researchers to do research in areas such as adaptation and factuality in multimodal and/or large language models. Feel free to contact me if you are interested (starting time is flexible).</strong></em>
          </p>
        </td>
      </tr>
      </tbody></table> -->


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tbody><tr>
        <td width="100%" valign="middle">
          <heading>News</heading>
          <p>  
            <!-- <li>I moved from Goolge Cloud AI Research team to Google DeepMind in August 2024.</li> -->
           <li>Our paper on <a href="https://arxiv.org/pdf/2405.18654"> hallucination mitigation in multimodal LLMs </a> is accepted at ICLR 2025</a>. </li>
            <li> I served as an Area Chair for <a href="https://cvpr.thecvf.com/"></a> CVPR 2025.
            <li>Our paper <a href="https://arxiv.org/abs/2411.19865"> Reverse Thinking Makes LLMs Stronger Reasoners</a> is accepted at NAACL 2025</a>. </li>              
            <li> I served as an Area Chair for <a href="https://eccv2024.ecva.net/"></a> ECCV 2024.
            <li>Our paper on <a href="https://arxiv.org/pdf/2312.01279"> efficient post-hoc explainability for LLMs</a> is accepted at ACL 2024</a>. </li>                
      <li> <a href="javascript:toggle_vis('news')">show more</a> </li>
      <div id="news" style="display:none">             
            <li> I served as a panalist in virtual ContinualAI Uncofernece in Oct. 2023! <a href="https://unconf.continualai.org/program/"></a>.
            <li>Our paper on <a href="https://arxiv.org/pdf/2310.11689.pdf"> selective prediction for LLMs</a> is accepted at EMNLP 2023</a>. Google blog post is <a href="https://blog.research.google/2024/01/introducing-aspire-for-selective.html"> here</a> </li>   
            <li>Our <a href="https://arxiv.org/pdf/2211.15646.pdf"> paper on test time adaptation</a> to address spurious correleations is accepted at NeurIPS 2023. Awesome collaboration with <a href="">Qingyao Sun, </a><a href="https://www.cs.ubc.ca/~murphyk/">Kevin Murphy, </a> and <a href="https://www.alexdamour.com/">Alexander D'Amour. </a> </li>            
            <li>New paper on introducing a new architecture and pretraining strategies for <a href="https://arxiv.org/abs/2305.16556"> multimodal learning with unstructured (vision and language) and structured (tabular and time series) data!</a> </li>
      <li>Our paper on <a href="https://openreview.net/forum?id=zshemTAa6U"> Test-Time Adaptation for Visual Document Understanding</a> got accepted at TMLR!  </li>
            <li>New  <a href="https://arxiv.org/abs/2304.03870"> paper on linking active learning and selective prediction!</a> </li>
            <li> Our <a href="https://arxiv.org/pdf/2204.04799.pdf"> new paper on Continual Learning</a> is accepted at ECCV 2022!</li> 
            <li> I have an invited talk at the <a href="https://rosecvpr22.github.io/index.html#invited-speakers">CVPR 22 workshop on Robustness in Sequential Data</a>.        
        <li> Our paper <a href="https://arxiv.org/pdf/2204.10377.pdf"> Contrastive Test-Time Adaptation </a> got accepted at CVPR 2022.</li> 
        <!-- <li> Our paper <a href="https://openreview.net/pdf?id=U8pbd00cCWB">Differentiable Gradient Sampling for 3D Scene Reconstructions</a> got accepted at ICLR 2022.</li>     -->
        <li>I joined <a href="https://research.google/teams/cloud-ai/"> Google Cloud AI Research</a> in November 2021!</li>
        <li>Our paper <a href="https://arxiv.org/pdf/2107.03315">Predicting with Confidence on Unseen Distributions</a> got accepted at ICCV 2021!</li>        
        <li>I gave an invited talk at the <a href="https://sites.google.com/view/clvision2021">CVPR 21 Workshop on Continual Learning in Computer Vision</a>. Video is <a href="https://youtu.be/NeqPhripSkI?t=817">here</a>. </li>
        <li>I gave an invited talk at Google AI, Facebook AI, and Amazon on "Active, continual, and adaptive learning".</li>
        <li>I was recognized as an Outstanding Reviewer at <a href="http://cvpr2021.thecvf.com/node/184">CVPR 2021</a>. </li>        
            <li> Our paper <a href="https://openreview.net/pdf?id=tHgJoMfy6nI">Remembering for the Right Reasons</a> got accepted at ICLR 2021</li>        
        <li> Our paper <a href="https://arxiv.org/pdf/2003.09553.pdf">Adversarial Continual Learning </a> got accepted at ECCV 2020</li>        
        <li> I graduated from both ME and EECS departments in May 2020 and started my postdoc at BAIR! </li></ul> 
      <li> I received <a href="https://www2.eecs.berkeley.edu/Students/Awards/11/?_ga=2.121718411.1669981988.1587577753-1589437370.1583733679">the Eugene L. Lawler Prize </a> from EECS department!</li>
        <font face="Helvetica, &#39;sans&#39;" size="3" color="black">
        <!-- <ul><li> New paper <a href="https://arxiv.org/pdf/2003.09553.pdf">"Adversarial Continual Learning" </a> on arXiv. <a href="https://github.com/facebookresearch/Adversarial-Continual-Learning">Code is also released!  </a></li></ul>  -->
        <font face="Helvetica, &#39;sans&#39;" size="3" color="black">        
        <li> I will be co-organizing the <a href="https://sites.google.com/view/cl-icml">Workshop on Continual Learning</a>, co-occuring with ICML 2020</li> 
        <font face="Helvetica, &#39;sans&#39;" size="3" color="black">            
       <li> Our paper <a href="https://openreview.net/pdf?id=HklUCCVKDB">Uncertainty-guided Continual Learning with Bayesian Neural Networks </a> got accepted at ICLR 2020</li>
        <li>I spent summer 2019 at Facebook AI Research in Menlo Park as an intern.</li> 
        <li> Our paper <a href="https://arxiv.org/abs/1904.00370">Variational Advarsarial Active Learning </a> got accepted at ICCV 2019 as on <font color="green"><strong>Oral</strong></font>! (4.3%) </li>          
        <li> I co-organized the <a href="https://wicvworkshop.github.io/CVPR2019/index.html#">6th Women in Computer Vision (WiCV) Workshop</a> , co-located with CVPR in June 2019</li>
        </div>
          </p>
        </td>
      </tr>
      </tbody></table>


<!--       <li> <a href="javascript:toggle_vis('news')">show more</a> </li>
      <div id="news" style="display:none"> 
        <li>Some of my research was featured in a <a href="https://techcrunch.com/video/teaching-robots-to-learn-how-to-learn/">TechCrunch article</a>.</li>
      </div> -->

<!--       <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tbody><tr>
        <td width="100%" valign="middle">
          <heading>Preprints</heading>
        </td>
      </tr>
      </tbody></table>

    <table width="120%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody>
      <tr>
        <td valign="top" width="75%">
          <p><a href="https://arxiv.org/pdf/2109.01087.pdf">
    <papertitle>On-target Adaptation </papertitle></a><br>
                        <a href="https://dequan.wang">Dequan Wang, </a> 
                    <a href="https://scholar.google.com/citations?user=v4JMf6kAAAAJ&hl=en">Shaoteng Liu, </a> 
                    <font color="black"><strong>Sayna Ebrahimi</strong></font>, 
                    <a href="http://imaginarynumber.net">Evan Shelhamer, </a> 
                    <a href="http://people.eecs.berkeley.edu/~trevor/">Trevor Darrell. </a><br>
            <!-- <em>ICLR</em>, 2022<br> -->
            <!-- <a href="https://github.com/">Code</a>, -->
<!--     </tr>
    <tr>
      <td valign="top" width="75%">
    <p><a href="https://arxiv.org/abs/2108.09186.pdf">
      <papertitle>Region-level Active Learning for Cluttered Scenes</papertitle></a><br>
                      <a href="https://scholar.google.com/citations?user=carZx9cAAAAJ&hl=en">Michael Laielli, </a> 
                      <a href="https://scholar.google.com/citations?user=s0Fof5IAAAAJ&hl=en">Giscard Biamby, </a> 
                      <a href="https://www.linkedin.com/in/dian-chen-robo8239158/">Dian Chen, </a> 
                      Adam Loeffler, Phat Dat Nguyen, Ross Luo, 
                      <a href="http://people.eecs.berkeley.edu/~trevor/">Trevor Darrell</a>,
                       <font color="black"><strong>Sayna Ebrahimi.</strong></font>
                      <br>
                      <!-- [<a href="https://arxiv.org/abs/2108.09186.pdf" >Paper</a>]  -->
              <!-- <em>ICLR</em>, 2022<br> -->
              <!-- <a href="https://github.com/">Code</a>, -->
<!--             </tr>
      <tr> 
      <td valign="top" width="75%">
        <p><a href="https://arxiv.org/abs/2012.10467.pdf">
        <papertitle>Minimax Active Learning</papertitle></a><br>
                                            <font color="black"><strong>Sayna Ebrahimi</strong></font>, 
                  <a href="https://wjgan.com">William Gan, </a> 
                  <a href="https://www.linkedin.com/in/dian-chen-robo8239158/">Dian Chen, </a>
                  <a href="https://scholar.google.com/citations?user=s0Fof5IAAAAJ&hl=en">Giscard Biamby, </a>
                  <a href="https://kamyar.io">Kamyar Salahi, </a>
                  <a href="https://scholar.google.com/citations?user=carZx9cAAAAJ&hl=en">Michael Laielli, </a>
                  <a href="https://zhusz.github.io/homepage/">Shizhan Zhu, </a>
                  <a href="http://people.eecs.berkeley.edu/~trevor/">Trevor Darrell. </a>
                  <br>
                  [<a href="https://people.eecs.berkeley.edu/~sayna/mal.html" >Project Page</a>]
          </tr>
          <tr> 

    </tbody></table> --> 
    


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tbody><tr>
        <td width="100%" valign="middle">
          <heading>Publications</heading>
        </td>
      </tr>
      </tbody></table>



      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody><tr onmouseout="doctta_stop()" onmouseover="doctta_start()">
          <td width="25%">

            <div class="one">
                <div class="two" id="halva" style="opacity: 0;"><img height="120" width="140" src="./index_files/halva/halva.jpg"></div>
                <img height="120" width="140" src="./index_files/halva/halva.jpg">
            </div>
            <script type="text/javascript">
            function doctta_start() {
              document.getElementById('halva').style.opacity = "1";
            }
            function doctta_stop() {
              document.getElementById('halva').style.opacity = "0";
            }
            doctta_stop()
            </script>
              </td>
              <td valign="top" width="75%">
              <p><a href="https://arxiv.org/pdf/2405.18654">
        <papertitle>Mitigating Object Hallucination in MLLMs via Data-augmented Phrase-level Alignment</papertitle></a><br>
                        <font> <a href="https://pritamsarkar.com/">Pritam Sarkar, </font></a>
                        <font color="black"><strong>Sayna Ebrahimi, </strong></font>
                        <a href="https://www.aiimlab.com/ali-etemad">Ali Etemad, </a>
                        <a href="https://sites.google.com/corp/view/beirami">Ahmad Beirami, </a>
                        <a href="https://sites.google.com/corp/view/sercanarik/home">Sercan O. Arik, </a> 
                        <a href="https://tomas.pfister.fi/">Tomas Pfister </a>                          
                        <br> 
                        <em>International Conference on Representation Learning <strong>(ICLR 2025)</strong></em>                        
                        <br>
              </p><p></p><p></p>
               A finetuning strategy to make MLLMs hallucinate less. 
              </p><p></p><p></p>
              <p></p>
              </td>
            </tr>
        </tbody></table>  



      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody><tr onmouseout="doctta_stop()" onmouseover="doctta_start()">
          <td width="25%">

            <div class="one">
                <div class="two" id="TextGenSHAP" style="opacity: 0;"><img height="120" width="140" src="./index_files/TextGenShap/TextGenShapa.jpg"></div>
                <img height="120" width="140" src="./index_files/TextGenShap/TextGenShapb.jpg">
            </div>
            <script type="text/javascript">
            function doctta_start() {
              document.getElementById('TextGenSHAP').style.opacity = "1";
            }
            function doctta_stop() {
              document.getElementById('TextGenSHAP').style.opacity = "0";
            }
            doctta_stop()
            </script>
              </td>
              <td valign="top" width="75%">
              <p><a href="https://arxiv.org/abs/2312.01279">
        <papertitle>TextGenSHAP: Scalable Post-hoc Explanations in Text Generation with Long Documents</papertitle></a><br>
                        <font> <a href="https://enouenj.github.io/">James Enouen, </font></a>
                        <a href="https://research.google/people/hootan-nakhost/">Hootan Nakhost, </a>
                        <font color="black"><strong>Sayna Ebrahimi, </strong></font>
                        <a href="https://sites.google.com/corp/view/sercanarik/home">Sercan O. Arik, </a> 
                        <a href="https://viterbi-web.usc.edu/~liu32/">Yan Liu, </a> 
                        <a href="https://tomas.pfister.fi/">Tomas Pfister </a>                          
                        <br> 
                        <!-- <em>Preprint <strong></strong></em> -->
                        <em>Annual Meeting of the Association for Computational Linguistics <strong>(Findings of ACL 2024) </strong></em>                        
                        <br>
              </p><p></p><p></p>
               A post-hoc XAI method for LLMs which extends Shapley value type methods to the scale of LLMs and long documents. 
              </p><p></p><p></p>
              <p></p>
              </td>
            </tr>
        </tbody></table>  


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody><tr onmouseout="doctta_stop()" onmouseover="doctta_start()">
          <td width="25%">

            <div class="one">
                <div class="two" id="lanistr" style="opacity: 0;"><img height="120" width="140" src="./index_files/lanistr/lanistr.jpg"></div>
                <img height="120" width="140" src="./index_files/lanistr/lanistr.jpg">
            </div>
            <script type="text/javascript">
            function doctta_start() {
              document.getElementById('lanistr').style.opacity = "1";
            }
            function doctta_stop() {
              document.getElementById('lanistr').style.opacity = "0";
            }
            doctta_stop()
            </script>
              </td>
              <td valign="top" width="75%">
              <p><a href="https://arxiv.org/abs/2305.16556">
        <papertitle>LANISTR: Multimodal Learning from Structured and Unstructured Data</papertitle></a><br>
                        <font color="black"><strong>Sayna Ebrahimi, </strong></font>
                        <a href="https://sites.google.com/corp/view/sercanarik/home">Sercan O. Arik, </a> 
                          <a href="https://yihedong.me/">Yihe Dong, </a>
                          <a href="https://tomas.pfister.fi/">Tomas Pfister </a>                          
                        <br>
                        [<a href="https://research.google/blog/lanistr-multimodal-learning-from-structured-and-unstructured-data/" >Google Blog</a>]
                        [<a href="https://github.com/google-research/lanistr" >Code</a>]
                        <br>
              </p><p></p><p></p>
               A novel architecture and pretraining strategies to learn from image, text, and time series/tabular data!
              </p><p></p><p></p>
              <p></p>
              </td>
            </tr>
        </tbody></table>  


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody><tr onmouseout="doctta_stop()" onmouseover="doctta_start()">
          <td width="25%">

            <div class="one">
                <div class="two" id="aspest" style="opacity: 0;"><img height="120" width="140" src="./index_files/aspest/aspest.jpg"></div>
                <img height="120" width="140" src="./index_files/aspest/aspest.jpg">
            </div>
            <script type="text/javascript">
            function doctta_start() {
              document.getElementById('aspest').style.opacity = "1";
            }
            function doctta_stop() {
              document.getElementById('aspest').style.opacity = "0";
            }
            doctta_stop()
            </script>
              </td>
              <td valign="top" width="75%">
              <p><a href="https://arxiv.org/abs/2304.03870">
        <papertitle>ASPEST: Bridging the Gap Between Active Learning and Selective Prediction</papertitle></a><br>
                        <a href="https://pages.cs.wisc.edu/~jiefeng/">Jiefeng Chen, </a>
                        <a href="https://sites.google.com/corp/view/jinsungyoon?pli=1">Jinsung Yoon, </a>   
                        <font color="black"><strong>Sayna Ebrahimi, </strong></font>
                        <a href="https://sites.google.com/corp/view/sercanarik/home">Sercan O. Arik, </a> 
                          <a href="https://pages.cs.wisc.edu/~jha/">Somesh Jha, </a>
                          <a href="https://tomas.pfister.fi/">Tomas Pfister </a>                          
                        <br>
                        <em>Transactions on Machine Learning Research<strong> (TMLR, 2024)</strong></em>
                        <!-- <em>International Conference on Representation Learning <strong>(ICLR 2024)</strong></em> -->
                        <br>
                        [<a href="https://github.com/google-research/google-research/tree/master/active_selective_prediction" >Code</a>]
                        <br>
              </p><p></p><p></p>
               A novel method to combine active learing and selective prediction. 
              </p><p></p><p></p>
              <p></p>
              </td>
            </tr>
        </tbody></table>




      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody><tr onmouseout="doctta_stop()" onmouseover="doctta_start()">
          <td width="25%">

            <div class="one">
                <div class="two" id="aspire" style="opacity: 0;"><img height="120" width="140" src="./index_files/aspire/aspire_1.jpg"></div>
                <img height="120" width="140" src="./index_files/aspire/aspire_2.jpg">
            </div>
            <script type="text/javascript">
            function doctta_start() {
              document.getElementById('aspire').style.opacity = "1";
            }
            function doctta_stop() {
              document.getElementById('aspire').style.opacity = "0";
            }
            doctta_stop()
            </script>
              </td>
              <td valign="top" width="75%">
              <p><a href="https://arxiv.org/pdf/2310.11689.pdf">
        <papertitle>Adaptation with Self-Evaluation to Improve Selective Prediction in LLMs</papertitle></a><br>
                        <a href="https://pages.cs.wisc.edu/~jiefeng/">Jiefeng Chen, </a>
                        <a href="https://sites.google.com/corp/view/jinsungyoon?pli=1">Jinsung Yoon, </a>   
                        <font color="black"><strong>Sayna Ebrahimi, </strong></font>
                        <a href="https://sites.google.com/corp/view/sercanarik/home">Sercan O. Arik, </a> 
                        <a href="https://tomas.pfister.fi/">Tomas Pfister, </a>  
                        <a href="https://pages.cs.wisc.edu/~jha/">Somesh Jha </a>                       
                        <br>
                        <em>Conference on Empirical Methods in Natural Language Processing <strong>(Findings of EMNLP 2023) </strong></em>
                        [<a href="https://blog.research.google/2024/01/introducing-aspire-for-selective.html" >Google Blog</a>]
                        <br>
                        <br>
              </p><p></p><p></p>
               LLMs can adapt themselves to have better selective prediction performance, that is to abstain from generating an answer when in doubt!
              </p><p></p><p></p>
              <p></p>
              </td>
            </tr>
        </tbody></table>    




      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody><tr onmouseout="doctta_stop()" onmouseover="doctta_start()">
          <td width="25%">

            <div class="one">
                <div class="two" id="ttlsa" style="opacity: 0;"><img height="120" width="140" src="./index_files/ttlsa/ttlsa.jpg"></div>
                <img height="120" width="140" src="./index_files/ttlsa/ttlsa.jpg">
            </div>
            <script type="text/javascript">
            function doctta_start() {
              document.getElementById('ttlsa').style.opacity = "1";
            }
            function doctta_stop() {
              document.getElementById('ttlsa').style.opacity = "0";
            }
            doctta_stop()
            </script>
              </td>
              <td valign="top" width="75%">
              <p><a href="https://arxiv.org/pdf/2211.15646.pdf">
        <papertitle>Beyond Invariance: Test-Time Label-Shift Adaptation for Distributions with Spurious Correlations</papertitle></a><br>
                        <a href="">Qingyao Sun, </a>
                        <a href="https://www.cs.ubc.ca/~murphyk/">Kevin Murphy, </a>   
                        <font color="black"><strong>Sayna Ebrahimi, </strong></font>
                          <a href="https://www.alexdamour.com/">Alexander D'Amour </a>
                        <br>
                        <em>Conference on Neural Information Processing SystemsPS <strong>(NeurIPS 2023)</strong></em>
                        [<a href="https://github.com/nalzok/test-time-label-shift" >Code</a>]
                        <br>
              </p><p></p><p></p>
               A novel test-time (source data-free) adaptation mechanism for label shift using <em>spurious</em> correlations. 
              </p><p></p><p></p>
              <p></p>
              </td>
            </tr>
        </tbody></table>

    




      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody><tr onmouseout="doctta_stop()" onmouseover="doctta_start()">
          <td width="25%">

            <div class="one">
                <div class="two" id="doctta_image" style="opacity: 0;"><img height="120" width="140" src="./index_files/doctta/doctta_a.jpg"></div>
                <img height="120" width="140" src="./index_files/doctta/doctta_b.jpg">
            </div>
            <script type="text/javascript">
            function doctta_start() {
              document.getElementById('doctta_image').style.opacity = "1";
            }
            function doctta_stop() {
              document.getElementById('doctta_image').style.opacity = "0";
            }
            doctta_stop()
            </script>
              </td>
              <td valign="top" width="75%">
              <p><a href="https://openreview.net/forum?id=zshemTAa6U">
        <papertitle>Test-Time Adaptation for Visual Document Understanding</papertitle></a><br>
                          <font color="black"><strong>Sayna Ebrahimi</strong></font>, 
                          <a href="https://sites.google.com/corp/view/sercanarik/home">Sercan O. Arik, </a> 
                          <a href="https://tomas.pfister.fi/">Tomas Pfister </a>
                        <br>
                        <em>Transactions on Machine Learning Research<strong> (TMLR, 2023)</strong></em>
                        <br>
                        [<a href="./DocTTA.html" >Project page</a>][<a href="https://drive.google.com/drive/u/1/folders/1Sy0kWgh3tph1bhq1NL3-xUWmVCPfXt-1" >Download benchmarks</a>]
                        <!-- [<a href="https://github.com/google-research/l2p" >Code</a>] -->
                        <br>
              </p><p></p><p></p>
               A novel test-time (source data-free) adaptation mechanism for a multimodal task (document understanding).
              </p><p></p><p></p>
              <p></p>
              </td>
            </tr>
        </tbody></table>



        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody><tr onmouseout="dualprompt_stop()" onmouseover="dualprompt_start()">
            <td width="25%">
  
              <div class="one">
                  <div class="two" id="dualprompt_image" style="opacity: 0;"><img height="120" width="140" src="./index_files/dualprompt/dualprompt_a.jpg"></div>
                  <img height="120" width="140" src="./index_files/dualprompt/dualprompt_b.jpg">
              </div>
              <script type="text/javascript">
              function dualprompt_start() {
                document.getElementById('dualprompt_image').style.opacity = "1";
              }
              function dualprompt_stop() {
                document.getElementById('dualprompt_image').style.opacity = "0";
              }
              dualprompt_stop()
              </script>
                </td>
                <td valign="top" width="75%">
                <p><a href="https://arxiv.org/pdf/2204.04799.pdf">
          <papertitle>DualPrompt: Complementary Prompting for Rehearsal-free Continual Learning</papertitle></a><br>        
          <a href="https://kingspencer.github.io/">Zifeng Wang, </a> 
          <a href="https://sites.google.com/corp/view/zizhaozhang/home">Zizhao Zhang, </a>         
           <font color="black"><strong>Sayna Ebrahimi</strong></font>, 
           <a href="https://scholar.google.com/citations?user=ut1-7LAAAAAJ&hl=en">Ruoxi Sun, </a>         
           <a href="https://sites.google.com/corp/view/hanzhang">Han Zhang, </a>  
           <a href="https://chl260.github.io/">Chen-Yu Lee,</a>  
           <a href="https://www.linkedin.com/in/xiaoqi-ren-898033a5/">Xiaoqi Ren,</a>  
           <a href="https://scholar.google.com/citations?user=XWLOtwQAAAAJ&hl=en">Guolong Su,</a>  
           <a href="https://research.google/people/VincentPerot/">Vincent Perot,</a>  
          <a href=" https://ece.northeastern.edu/fac-ece/jdy/"> Jennifer Dy, </a>
          <a href="https://tomas.pfister.fi/">Tomas Pfister, </a>
                          <br>
                          <em>European Conference on Computer Vision <strong>(ECCV 2022)</strong></em>
                          <br>
                          [<a href="https://github.com/google-research/l2p" >Code</a>]
                          <br>
                </p><p></p><p></p>
                 A rehearsal-free approach for using prompts in continual learning.
                </p><p></p><p></p>
                <p></p>
                </td>
              </tr>
          </tbody></table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody><tr onmouseout="doc_stop()" onmouseover="doc_start()">
          <td width="25%">

            <div class="one">
                <div class="two" id="doc_image" style="opacity: 0;"><img height="120" width="140" src="./index_files/doc/doc1.png"></div>
                <img height="120" width="140" src="./index_files/doc/doc2.png">
            </div>
            <script type="text/javascript">
            function doc_start() {
              document.getElementById('doc_image').style.opacity = "1";
            }
            function doc_stop() {
              document.getElementById('doc_image').style.opacity = "0";
            }
            doc_stop()
            </script>
              </td>
              <td valign="top" width="75%">
              <p><a href="https://arxiv.org/pdf/2204.10377.pdf">
        <papertitle>Contrastive Test-Time Adaptation</papertitle></a><br>
                        <a href="https://www.linkedin.com/in/dian-chen-robo8239158/">Dian Chen, </a>
                        <a href="https://dequan.wang">Dequan Wang, </a> 
                        <a href="http://people.eecs.berkeley.edu/~trevor/">Trevor Darrell, </a>
                        <font color="black"><strong>Sayna Ebrahimi</strong></font>, 
                        <br>
                        <em>Computer Vision and Pattern Recognition Conference <strong>(CVPR 2022)</strong></em>
                        <br>
                        [<a href="https://sites.google.com/corp/view/adacontrast" >Project page</a>] [<a href="https://github.com/DianCh/AdaContrast" >Code</a>]
                        <br>
              </p><p></p><p></p>
              Test-time adaptation using contrstive learning and self training! 
              </p><p></p><p></p>
              <p></p>
              </td>
            </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody><tr onmouseout="dgs_stop()" onmouseover="dgs_start()">
            <td width="25%">
  
              <div class="one">
                  <div class="two" id="dgs_image" style="opacity: 0;"><img height="120" width="140" src="./index_files/dgs/iclr22_a.jpeg"></div>
                  <img height="120" width="140" src="./index_files/dgs/iclr22_b.jpeg">
              </div>
              <script type="text/javascript">
              function dgs_start() {
                document.getElementById('dgs_image').style.opacity = "1";
              }
              function dgs_stop() {
                document.getElementById('dgs_image').style.opacity = "0";
              }
              dgs_stop()
              </script>
                </td>
                <td valign="top" width="75%">
                <p><a href="https://openreview.net/pdf?id=U8pbd00cCWB">
          <papertitle>Differentiable Gradient Sampling for Learning Implicit 3D Scene Reconstructions from a Single Image</papertitle></a><br>
                          <a href="https://zhusz.github.io/homepage/">Shizhan Zhu, </a> 
                           <font color="black"><strong>Sayna Ebrahimi</strong></font>, 
                           <a href="http://people.eecs.berkeley.edu/~kanazawa/">Angjoo Kanazawa </a>                           
                          <a href="http://people.eecs.berkeley.edu/~trevor/">Trevor Darrell, </a>
                          <br>
                          <em>International Conference on Representation Learning <strong>(ICLR 2022)</strong></em>
                          <br>
                          [<a href="https://zhusz.github.io/ICLR22-DGS-Webpage/" >Project page</a>] [<a href="https://github.com/zhusz/ICLR22-DGS" >Code</a>]
                          <br>
                </p><p></p><p></p>
                 Implicit 3D recontruction using a novel diffretiable gradient sampling.
                </p><p></p><p></p>
                <p></p>
                </td>
              </tr>
          </tbody></table>
          
          
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody><tr onmouseout="hpt_stop()" onmouseover="hpt_start()">
          <td width="25%">

            <div class="one">
                <div class="two" id="hpt_image" style="opacity: 0;"><img height="100" width="210" src="./index_files/hpt/hpt_1.png"></div>
                <img height="100" width="210" src="./index_files/hpt/hpt_2.png">
            </div>
            <script type="text/javascript">
            function hpt_start() {
              document.getElementById('hpt_image').style.opacity = "1";
            }
            function hpt_stop() {
              document.getElementById('hpt_image').style.opacity = "0";
            }
            hpt_stop()
            </script>
              </td>
              <td valign="top" width="75%">
              <p><a href="https://arxiv.org/pdf/2103.12718.pdf">
        <papertitle>Self-Supervised Pretraining Improves Self-Supervised Pretraining</papertitle></a><br>
                        <a href="https://people.eecs.berkeley.edu/~cjrd/">Colorado Reed*, </a> 
                        <a href="http://people.eecs.berkeley.edu/~xyyue/">Xiangyu Yue*, </a> 
                        <a href="https://www.linkedin.com/in/aniruddha-nrusimha/">Ani Nrusimha, </a> 
                          <font color="black"><strong>Sayna Ebrahimi</strong></font>, 
                        <a href="https://www.linkedin.com/in/vivek-vijaykumar/">Vivek Vijaykumar, </a> 
                        <a href="https://www.linkedin.com/in/richard-mao/">Richard Mao, </a>
                        <a href="https://sites.google.com/view/luodian">Bo Li, </a>
                        <a href="https://www.linkedin.com/in/shanghang-zhang-4b5b226a/">Shanghang Zhang, </a>
                        <a href="http://www.devinguillory.com">Devin Guillory, </a>
                        <a href="https://scholar.google.com/citations?user=tu9gL58AAAAJ&hl=en">Sean Metzger, </a>
                        <a href="https://people.eecs.berkeley.edu/~keutzer/">Kurt Keutzer, </a>
                        <a href="http://people.eecs.berkeley.edu/~trevor/">Trevor Darrell </a>
                        <br>
                        <em>Winter Conference on Applications of Computer Vision <strong>(WACV 2022)</strong></em>
                        <br>
                        [<a href="https://github.com/cjrd/self-supervised-pretraining" >Code</a>]
              </p><p></p><p></p>
              Hierchical self-supervised pretraining improves pretraining itself!
              </p><p></p><p></p>
              <p></p>
              </td>
            </tr>
        </tbody></table>



        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody><tr onmouseout="ontarget_stop()" onmouseover="ontarget_start()">
            <td width="25%">
  
              <div class="one">
                  <div class="two" id="ontarget_image" style="opacity: 0;"><img src="./index_files/ontarget/visdac_test.png"></div>
                  <img src="./index_files/ontarget/visdac_train.png">
              </div>
              <script type="text/javascript">
              function ontarget_start() {
                document.getElementById('ontarget_image').style.opacity = "1";
              }
              function ontarget_stop() {
                document.getElementById('ontarget_image').style.opacity = "0";
              }
              ontarget_stop()
              </script>
  
                </td>
                <td valign="top" width="75%">
                <p><a href="https://arxiv.org/pdf/2109.01087.pdf">
          <papertitle>On-target Adaptation </papertitle></a><br>
                              <a href="https://dequan.wang">Dequan Wang, </a> 
                          <a href="https://scholar.google.com/citations?user=v4JMf6kAAAAJ&hl=en">Shaoteng Liu, </a> 
                          <font color="black"><strong>Sayna Ebrahimi</strong></font>, 
                          <a href="http://imaginarynumber.net">Evan Shelhamer, </a> 
                          <a href="http://people.eecs.berkeley.edu/~trevor/">Trevor Darrell </a><br>
                          <strong>(arXiv 2021)</strong><br>
                  <!-- <a href="https://github.com/">Code</a>, -->
                </p><p></p>
                Improving performance on unseen data using InfoMax loss, self-training, and knowledge ditillation across domains.  
                </p><p></p>
                </td>
              </tr>
          </tbody></table>
            
            
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody><tr onmouseout="real_stop()" onmouseover="real_start()">
              <td width="25%">
    
                <div class="one">
                    <div class="two" id="real_image" style="opacity: 0;"><img height="120" width="200" src="./index_files/ReAL/ReAL_main6.png"></div>
                    <img height="120" width="200" src="./index_files/ReAL/tiled.png">
                </div>
                <script type="text/javascript">
                function real_start() {
                  document.getElementById('real_image').style.opacity = "1";
                }
                function real_stop() {
                  document.getElementById('real_image').style.opacity = "0";
                }
                real_stop()
                </script>
                  </td>
                  <td valign="top" width="75%">
                  <p><a href="https://arxiv.org/abs/2108.09186.pdf">
            <papertitle>Region-level Active Learning for Cluttered Scenes</papertitle></a><br>
                            <a href="https://scholar.google.com/citations?user=carZx9cAAAAJ&hl=en">Michael Laielli, </a> 
                            <a href="https://scholar.google.com/citations?user=s0Fof5IAAAAJ&hl=en">Giscard Biamby, </a> 
                            <a href="https://www.linkedin.com/in/dian-chen-robo8239158/">Dian Chen, </a> 
                            Adam Loeffler, Phat Dat Nguyen, Ross Luo, 
                            <a href="http://people.eecs.berkeley.edu/~trevor/">Trevor Darrell</a>,
                             <font color="black"><strong>Sayna Ebrahimi</strong></font>
                            <br>
                            <strong>(arXiv 2021)</strong><br>
                            <!-- [<a href="https://arxiv.org/abs/2108.09186.pdf" >Paper</a>]  -->
                    <!-- <em>ICLR</em>, 2022<br> -->
                    <!-- <a href="https://github.com/">Code</a>, -->
                  </p><p></p><p></p>
                  Novel generalized active learning framework for object detection at region level on real-world noisy imbalanced cluttered datasets
                  </p><p></p><p></p>
                  <p></p>
                  </td>
                </tr>
            </tbody></table>
            
            
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody><tr onmouseout="doc_stop()" onmouseover="doc_start()">
          <td width="25%">

            <div class="one">
                <div class="two" id="doc_image" style="opacity: 0;"><img height="120" width="140" src="./index_files/doc/doc1.png"></div>
                <img height="120" width="140" src="./index_files/doc/doc2.png">
            </div>
            <script type="text/javascript">
            function doc_start() {
              document.getElementById('doc_image').style.opacity = "1";
            }
            function doc_stop() {
              document.getElementById('doc_image').style.opacity = "0";
            }
            doc_stop()
            </script>
              </td>
              <td valign="top" width="75%">
              <p><a href="https://arxiv.org/pdf/2107.03315.pdf">
        <papertitle>Predicting with Confidence on Unseen Distributions</papertitle></a><br>
                        <a href="http://www.devinguillory.com">Devin Guillory, </a> 
                        <a href="http://vaishaal.com">Vaishaal Shankar, </a>
                         <font color="black"><strong>Sayna Ebrahimi</strong></font>, 
                        <a href="http://people.eecs.berkeley.edu/~trevor/">Trevor Darrell, </a>
                        <a href="http://people.csail.mit.edu/ludwigs/">Ludwig Schmidt </a>
                        <br>
                        <em>International Conference on Computer Vision <strong>(ICCV 2021)</strong></em>
                        <br>
              </p><p></p><p></p>
              Predicting accuracy on unseen data distributions! 
              </p><p></p><p></p>
              <p></p>
              </td>
            </tr>
        </tbody></table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody><tr onmouseout="rrr_stop()" onmouseover="rrr_start()">
          <td width="25%">

            <div class="one">
                <div class="two" id="rrr_image" style="opacity: 0;"><img height="120" width="140" src="./index_files/rrr/rrr1.jpg"></div>
                <img height="120" width="140" src="./index_files/rrr/rrr2.jpg">
            </div>
            <script type="text/javascript">
            function rrr_start() {
              document.getElementById('rrr_image').style.opacity = "1";
            }
            function rrr_stop() {
              document.getElementById('rrr_image').style.opacity = "0";
            }
            rrr_stop()
            </script>
              </td>
              <td valign="top" width="75%">
              <p><a href="https://arxiv.org/pdf/2010.01528.pdf">
        <papertitle>Remembering for the Right Reasons: Explanations Reduce Catastrophic Forgetting</papertitle></a><br>
                        <font color="black"><strong>Sayna Ebrahimi</strong></font>,
                        <a href="https://spetryk.github.io">Suzanne Petryk, </a> 
                        <a href="https://scholar.google.com/citations?user=MYRUJkUAAAAJ&hl=en">Akash Gokul, </a>
                        <a href="https://wjgan.com">William Gan, </a> 
                        <a href="https://people.eecs.berkeley.edu/~jegonzal/">Joseph E. Gonzalez, </a>
                        <a href="http://rohrbach.vision">Marcus Rohrbach, </a>
                        <a href="http://people.eecs.berkeley.edu/~trevor/">Trevor Darrell </a>
                        <br>
                        [<a href="https://github.com/SaynaEbrahimi/Remembering-for-the-Right-Reasons" >Code</a>]
                        <br>
                        <em>International Conference on Representation Learning <strong>(ICLR 2021)</strong></em>
                        <br>
              </p><p></p><p></p>
              A hybrid continual learning algorithm that mitigates forgetting by using experience replay and explanation replay! 
              </p><p></p><p></p>
              <p></p>
              </td>
            </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody><tr onmouseout="mal_stop()" onmouseover="mal_start()">
            <td width="25%">
  
              <div class="one">
                  <div class="two" id="mal_image" style="opacity: 0;"><img height="120" width="140" src="./index_files/mal/mal1.png"></div>
                  <img height="120" width="140" src="./index_files/mal/mal2.png">
              </div>
              <script type="text/javascript">
              function mal_start() {
                document.getElementById('mal_image').style.opacity = "1";
              }
              function mal_stop() {
                document.getElementById('mal_image').style.opacity = "0";
              }
              mal_stop()
              </script>
                </td>
                <td valign="top" width="75%">
                <p><a href="https://arxiv.org/abs/2012.10467.pdf">
          <papertitle>Minimax Active Learning</papertitle></a><br>
                                                   <font color="black"><strong>Sayna Ebrahimi</strong></font>, 
                          <a href="https://wjgan.com">William Gan, </a> 
                          <a href="https://www.linkedin.com/in/dian-chen-robo8239158/">Dian Chen, </a>
                          <a href="https://scholar.google.com/citations?user=s0Fof5IAAAAJ&hl=en">Giscard Biamby, </a>
                          <a href="https://kamyar.io">Kamyar Salahi, </a>
                          <a href="https://scholar.google.com/citations?user=carZx9cAAAAJ&hl=en">Michael Laielli, </a>
                          <a href="https://zhusz.github.io/homepage/">Shizhan Zhu, </a>
                          <a href="http://people.eecs.berkeley.edu/~trevor/">Trevor Darrell </a>
                          <br>
                          [<a href="https://people.eecs.berkeley.edu/~sayna/mal.html" >Project Page</a>][<strong>arXiv 2020</strong>]
                </p><p></p><p></p>
                A semisupervisd active learning algorithm using minimax entropy that selects samples based on their diversity and uncertainty. 
                </p><p></p><p></p>
                <p></p>
                </td>
              </tr>
          </tbody></table>        


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody><tr onmouseout="acl_stop()" onmouseover="acl_start()">
          <td width="25%">

            <div class="one">
                <div class="two" id="acl_image" style="opacity: 0;"><img height="120" width="140" src="./index_files/acl/ACL1.jpg"></div>
                <img height="120" width="140" src="./index_files/acl/ACL2.jpg">
            </div>
            <script type="text/javascript">
            function acl_start() {
              document.getElementById('acl_image').style.opacity = "1";
            }
            function acl_stop() {
              document.getElementById('acl_image').style.opacity = "0";
            }
            acl_stop()
            </script>
              </td>
              <td valign="top" width="75%">
              <p><a href="https://arxiv.org/pdf/2003.09553.pdf">
        <papertitle>Adversarial Continual Learning</papertitle></a><br>
                        <font color="black"><strong>Sayna Ebrahimi</strong></font>, <a href="https://am.is.tuebingen.mpg.de/person/fmeier">Franziska Meier, </a> <a href="https://www.robertocalandra.com/about/">Roberto Calandra</a>, <a href="http://people.eecs.berkeley.edu/~trevor/">Trevor Darrell, </a> <a href="http://rohrbach.vision">Marcus Rohrbach </a><br>
                        <em>European Conference on Computer Vision <strong>(ECCV 2020)</strong></em>
                        <br>
                        [<a href="https://arxiv.org/pdf/2003.09553.pdf" >Paper</a>]
                        [<a href="https://github.com/facebookresearch/Adversarial-Continual-Learning" >Code</a>
                        ]                        
                        [<a href="https://youtu.be/DvfMmKu7GKE">Long Video</a>]
                        [<a href="https://youtu.be/_V8-6sa4kh0">Short Video</a>]
                        [<a href="./index_files/acl/slides.pdf">Slides</a>]
              </p><p></p><p></p>
              A hybrid continual learning algorithm that mitigates forgetting by using architecture growth and memory replay! 
              </p><p></p><p></p>
              <p></p>
              </td>
            </tr>
        </tbody></table>




      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody><tr onmouseout="ucb_stop()" onmouseover="ucb_start()">
          <td width="25%">

            <div class="one">
                <div class="two" id="ucb_image" style="opacity: 0;"><img height="120" width="140" src="./index_files/ucb/ucb1.png"></div>
                <img height="120" width="140" src="./index_files/ucb/ucb2.jpg">
            </div>
            <script type="text/javascript">
            function ucb_start() {
              document.getElementById('ucb_image').style.opacity = "1";
            }
            function acl_stop() {
              document.getElementById('ucb_image').style.opacity = "0";
            }
            ucb_stop()
            </script>
              </td>
              <td valign="top" width="75%">
              <p><a href="https://openreview.net/pdf?id=HklUCCVKDB">
        <papertitle>Uncertainty-Guided Continual Learning in Bayesian Neural Networks</papertitle></a><br>
                        <font color="black"><strong>Sayna Ebrahimi</strong></font> , <a href="https://sites.google.com/site/mhelhoseiny/" > Mohamed Elhoseiny,</a> <a href="http://people.eecs.berkeley.edu/~trevor/" >Trevor Darrell, </a> <a href="http://rohrbach.vision" > Marcus Rohrbach </a><br>
                        <em> International Conference on Learning Representations <strong>(ICLR 2020)</strong>. </em> 
                        <br>
                        [<a href="https://openreview.net/pdf?id=HklUCCVKDB" >Paper</a>]
                        [<a href="https://github.com/SaynaEbrahimi/UCB" >Code</a>]
            [<a href="https://iclr.cc/virtual_2020/poster_HklUCCVKDB.html" >Talk Video</a>]                        
                        [<a href="https://sites.google.com/berkeley.edu/ucb/home" >Project Page</a>]
              </p><p></p><p></p>
              A regularization-based continual learning algorithm that mitigates forgetting in Bayesian neural networks using uncertainty! 
              </p><p></p><p></p>
              <p></p>
              </td>
            </tr>
        </tbody></table>



      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody><tr onmouseout="compos_stop()" onmouseover="compos_start()">
          <td width="25%">

            <div class="one">
                <div class="two" id="compos_image" style="opacity: 0;"><img height="120" width="140" src="./index_files/compositionalGAN/nips2018.png"></div>
                <img height="120" width="140" src="./index_files/compositionalGAN/nips2018.png">
            </div>
            <script type="text/javascript">
            function compos_start() {
              document.getElementById('compos_image').style.opacity = "1";
            }
            function compos_stop() {
              document.getElementById('compos_image').style.opacity = "0";
            }
            compos_stop()
            </script>
              </td>
              <td valign="top" width="75%">
              <p><a href="https://arxiv.org/pdf/1807.07560.pdf">
        <papertitle>Compositional GAN: Learning Conditional Image Composition </papertitle></a><br>
                        <a href="https://people.eecs.berkeley.edu/~sazadi/" >Samaneh Azadi</a>, <a href="http://people.eecs.berkeley.edu/~pathak/">Deepak Pathak</a>,<font color="black"><strong> Sayna Ebrahimi</strong></font>, <a href="http://people.eecs.berkeley.edu/~trevor/">Trevor Darrell</a>        <br>
                        <em>International Journal of Computer Vision <strong>(IJCV 2020)</strong><br></em>
                        [<a href="https://arxiv.org/pdf/1807.07560.pdf" >Paper</a>]
                        [<a href="https://github.com/azadis/CompositionalGAN" >Code</a>]
              </p><p></p><p></p>
               Genrating realistic images by composing pair of objects from distinct distributions!
              </p><p></p><p></p>
              <p></p>
              </td>
            </tr>
        </tbody></table>



      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody><tr onmouseout="vaal_stop()" onmouseover="vaal_start()">
          <td width="25%">

            <div class="one">
                <div class="two" id="vaal_image" style="opacity: 0;"><img height="120" width="140" src="./index_files/vaal/teaser.jpg"></div>
                <img height="120" width="140" src="./index_files/vaal/vaal.jpg">
            </div>
            <script type="text/javascript">
            function vaal_start() {
              document.getElementById('vaal_image').style.opacity = "1";
            }
            function vaal_stop() {
              document.getElementById('vaal_image').style.opacity = "0";
            }
            vaal_stop()
            </script>
              </td>
              <td valign="top" width="75%">
              <p><a href="https://arxiv.org/abs/1904.00370.pdf">
        <papertitle>Variational Adversarial Active Learning </papertitle></a><br>
          <font color="black"><strong>Sayna Ebrahimi<span>&#42;</span></strong></font>, <a href = "https://www.samsinha.me" /a> Samarth Sinha<span>&#42;</span>, <a href="http://people.eecs.berkeley.edu/~trevor/">Trevor Darrell</a> <br>
                          <em> *denotes equal contribution.</em>  <br>
                          <em>Internation Conference on Compute Vision <strong>(ICCV 2019)</strong> <font color="green"><strong>(Oral)</strong></font></em></a>
                          <br>
                          [<a href="https://arxiv.org/abs/1904.00370" >Paper</a>]
                         [<a href="https://github.com/sinhasam/vaal" >Code</a>]
                         [<a href="https://conftube.com/video/xzygVl7ZncQ?tocitem=2" >Talk Video</a>]
                        [<a href="./index_files/vaal/poster" >Poster</a>]
                        [<a href="https://sites.google.com/berkeley.edu/vaal/home" >Project page</a>]
              </p><p></p><p></p>
               A novel task-agnostic active learning strategy that uses unsupervised learning (image reconstruction) to select samples.
              </p><p></p><p></p>
              <p></p>
              </td>
            </tr>
        </tbody></table>



      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody><tr onmouseout="gzsl_stop()" onmouseover="gzsl_start()">
          <td width="25%">

            <div class="one">
                <div class="two" id="gzsl_image" style="opacity: 0;"><img height="120" width="140" src="./index_files/gzsl/gzsl.jpg"></div>
                <img height="120" width="140" src="./index_files/gzsl/iclr_gzsl.png">
            </div>
            <script type="text/javascript">
            function gzsl_start() {
              document.getElementById('gzsl_image').style.opacity = "1";
            }
            function gzsl_stop() {
              document.getElementById('gzsl_image').style.opacity = "0";
            }
            gzsl_stop()
            </script>
              </td>
              <td valign="top" width="75%">
              <p><a href="https://arxiv.org/pdf/1812.01784.pdf">
        <papertitle>Generalized Zero and Few-Shot Learning via Aligned Variational Autoencoders </papertitle></a><br>
<a href="https://scholar.google.nl/citations?user=tvgSaXsAAAAJ&hl=en">Edgar Schonfeld</a>, <font color="black"><strong>Sayna Ebrahimi</strong></font> </a>, <a href = "https://www.samsinha.me" /a> Samarth Sinha, <a href="http://people.eecs.berkeley.edu/~trevor/" >Trevor Darrell, </a> <a href="https://ivi.fnwi.uva.nl/uvaboschdeltalab/people/zeynep-akata/" > Zeynep Akata </a>  <br>
                          <em>Computer Vision and Pattern Recognition Conference <strong>(CVPR 2019)</strong></em>
                          <br>            
                        [<a href="https://arxiv.org/pdf/1812.01784.pdf">Paper</a>]
                        [<a href="https://github.com/edgarschnfld/CADA-VAE-PyTorch" >Code</a>]                        
                        <!-- [<a href="confidence.html" >Project page</a>]</span> -->
              </p><p></p><p></p>
               A novel few/zero shot learning algorithm that uses different modalities.
              </p><p></p><p></p>
              <p></p>
              </td>
            </tr>
        </tbody></table>



      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody><tr onmouseout="corl_stop()" onmouseover="corl_start()">
          <td width="25%">

            <div class="one">
                <div class="two" id="corl_image" style="opacity: 0;"><img height="120" width="140" src="./index_files/corl17/gta.jpg"></div>
                <img height="120" width="140" src="./index_files/corl17/networks.jpg">
            </div>
            <script type="text/javascript">
            function corl_start() {
              document.getElementById('corl_image').style.opacity = "1";
            }
            function corl_stop() {
              document.getElementById('corl_image').style.opacity = "0";
            }
            corl_stop()
            </script>
              </td>
              <td valign="top" width="75%">
              <p><a href="https://arxiv.org/pdf/1710.05958.pdf">
        <papertitle>Gradient-free Policy Architecture Search and Adaptation </papertitle></a><br>
<font color="black"><strong>Sayna Ebrahimi</strong></font>, <a href="https://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/people/anna-rohrbach/" >Anna Rohrbach</a>, <a href="http://people.eecs.berkeley.edu/~trevor/" >Trevor Darrell</a>        <br>
                        <em> Conference on Robot Learning <strong>(CoRL 2017)</strong> </em><a href="https://www.youtube.com/embed/xfyK03MEZ9Q?rel=0&amp;start=10876&end=11295"> <font color="green"><strong>(Spotlight)</strong></font> </a> <br>
                        [<a href="https://arxiv.org/pdf/1710.05958.pdf" >Paper</a>]
                        [<a href="corl.html" >Project page</a>]
                        [<a href="https://scholar.googleusercontent.com/scholar.bib?q=info:2jAEaO8MBi0J:scholar.google.com/&output=citation&scisdr=CgXNGfQWEMTI7JiSnD4:AAGBfm0AAAAAXXiXhD624YiG33yIFbyHLeI8ijO7p0Uo&scisig=AAGBfm0AAAAAXXiXhCJTQhZMWMMwfN-CZ0zlKwxehzMO&scisf=4&ct=citation&cd=-1&hl=en" >Bibtex</a>]
              </p><p></p><p></p>
               Neural architecture search using gradient-free optimization to adapt from supervised learning to reward-based learning.
              </p><p></p><p></p>
              <p></p>
              </td>
            </tr>
        </tbody></table>


        <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody><tr>
            <td width="100%" valign="middle">
              <heading>Preprints</heading>
            </td>
          </tr>
          </tbody></table> -->
    
    <!--       <table width="120%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td valign="top" width="75%">
                  <p><a href="https://arxiv.org/pdf/2103.12718.pdf">
            <papertitle>Self-Supervised Pretraining Improves Self-Supervised Pretraining</papertitle></a><br>
                            <a href="https://people.eecs.berkeley.edu/~cjrd/">Colorado Reed*, </a> 
                            <a href="http://people.eecs.berkeley.edu/~xyyue/">Xiangyu Yue*, </a> 
                            <a href="https://www.linkedin.com/in/aniruddha-nrusimha/">Ani Nrusimha, </a> 
                             <font color="black"><strong>Sayna Ebrahimi</strong></font>, 
                            <a href="https://www.linkedin.com/in/vivek-vijaykumar/">Vivek Vijaykumar, </a> 
                            <a href="https://www.linkedin.com/in/richard-mao/">Richard Mao, </a>
                            <a href="https://sites.google.com/view/luodian">Bo Li, </a>
                            <a href="https://www.linkedin.com/in/shanghang-zhang-4b5b226a/">Shanghang Zhang, </a>
                            <a href="http://www.devinguillory.com">Devin Guillory, </a>
                            <a href="https://scholar.google.com/citations?user=tu9gL58AAAAJ&hl=en">Sean Metzger, </a>
                            <a href="https://people.eecs.berkeley.edu/~keutzer/">Kurt Keutzer, </a>
                            <a href="http://people.eecs.berkeley.edu/~trevor/">Trevor Darrell </a>
                            <br>
                            <em>Winter Conference on Applications of Computer Vision <strong>(WACV 2022)</strong></em>
                            [<a href="https://github.com/cjrd/self-supervised-pretraining" >Code</a>]
            </tr>
     -->
    
    

    
    
    

    


<BR /> <BR /><BR /> <BR />
<!--         <font face="Helvetica Neue, &#39;sans serif&#39;" size="5" color=#4682B4>
            <b>Theses</b>
        </font> -->  

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tbody><tr>
        <td width="100%" valign="middle">
          <heading>Theses</heading>
        </td>
      </tr>
      </tbody></table>

        <font face="Helvetica Neue, &#39;sans serif&#39;" color="black">
            <table cellspacing="25">
                <tbody>
                 <tr>
                     <td width="35%" align=left>
                         <img height="200" width="200" align="center" src="./berkeley_seal.png" border="0">
                     <td>
                         <BR /><BR />
                         <span style="font-size: 13pt;">
                         <b>  Continual Learning with Neural Networks </b><br>
                         <span style="font-size: 12pt;">
                         <font color="black"><strong>Sayna Ebrahimi<span></span></strong>; Spring 2020</font></a> <br>
                          <!-- [<a href="./index_files/cs-thesis.pdf" src="./index_files/cs-thesis.pdf" >Paper</a>] -->
                          [<a href="https://www2.eecs.berkeley.edu/Pubs/TechRpts/2020/EECS-2020-82.pdf" >Computer Science</a>]
                         <BR /><BR />
                          <b>  Mechanical Behavior of Materials at Multiscale: Peridynamic Theory and Learning-based Approaches </b><br>
                         <span style="font-size: 12pt;">
                         <font color="black"><strong>Sayna Ebrahimi<span></span></strong>; Spring 2020</font></a> <br>
                          [<a href="./index_files/PhD_thesis.pdf" src="./index_files/PhD_thesis.pdf" >Mechcanical Engineering</a>]
                     </td>
                 </tr>

             </tbody></table>
        </font>


<!--       <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tbody><tr>
        <td>
        <heading>Talks</heading>
        </td>
      </tr>
      </tbody></table>
      <table width="100%" align="center" border="0" cellpadding="20">
      <tbody><tr>
        <td width="75%" valign="center">
        <p> <a href="https://slideslive.com/38938215/an-inference-perspective-on-metareinforcement-learning ">An Inference Perspective on Meta-Reinforcement Learning</a> - An invited talk at the Neurips 2020 <a href="https://meta-learn.github.io/2020/">Workshop on Meta-Learning</a>. I make a case for why viewing meta-RL as task inference is a fruitful direction for future research in meta-RL.</p>
        <p> <a href="https://www.youtube.com/watch?v=VFRkByHnInY">An Inference Perspective on Meta-Learning</a> - An invited talk at the Sheffield Seminar, a weekly seminar of the <a href="https://www.sheffield.ac.uk/dcs/research/groups/machine-learning">Machine Learning group</a> at Sheffield University. I talk about how meta-learning as inference leads to effective algorithms for few-shot learning not just in RL, but also in image segmentation.</p>
        <p> <a href="https://www.youtube.com/watch?v=4qH_h5_V3O4&list=PLkFD6_40KJIwhWJpGazJ9VSj9CFMkb79A&index=19">An Overview of Meta-Reinforcement Learning</a> - A guest lecture presenting an overview of meta-RL in the Fall 2019 offering of CS294 at UC Berkeley</p>
        <p> <a href="https://www.youtube.com/watch?v=k6rL4wzykGA&list=PLoROMvodv4rMC6zfYmnD7UG3LVvwaITY5&index=7">Exploration in Meta-RL</a> - A guest lecture looking at the problem of exploration in meta-RL in the Fall 2019 offering of CS330 at Stanford University</p>
        <p> Efficient Meta-RL with Probabilistic Context Embeddings - contributed talk to the Workshop on Structure and Priors in RL at ICLR 2019</p>
        </p>
        </td>
      </tr>
      </tbody></table> -->

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tbody><tr>
        <td>
        <br>
        <p align="right"><font size="2">
          <a href="http://www.cs.berkeley.edu/~barron/">(this guy makes a nice wesbite)</a>
        </td>
      </tr>
      </tbody></table>
      <script type="text/javascript">
      var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
          document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));

      </script><script src="./jon_barron_website_files/ga.js" type="text/javascript"></script> <script type="text/javascript">
      try {
          var pageTracker = _gat._getTracker("UA-7580334-1");
          pageTracker._trackPageview();
          } catch(err) {}
      </script>
    </td>
    </tr>
  </tbody></table>


</body></html>
